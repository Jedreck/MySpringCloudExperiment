### 架构

#### master选举

 [es怎么实现master选举](https://blog.csdn.net/ailiandeziwei/article/details/87856210) 



#### 文档写入流程

 [深入理解ElasticSearch写入过程](https://elasticsearch.cn/article/13533) 

### 索引

#### 使用别名进行索引有什么用

实现索引热重建切换，程序里不受影响，能非常优雅的解决两个索引无缝切换的问题。

比如电商的核心商品索引库，除了实时增量数据外，每天都要重建一遍索引，避免index里面的数据和db里面的数据不一致，因为index分shard了，所以要一个一个的shard做全量替换，直到所有的shard替换完毕，才能宣布重建成功。整个过程其实还是风险挺大的，虽然每次只替换一个shard把风险量降到最低，但如果第3个或第4个shard重建有问题，有可能要回滚整个索引，这个问题其实用索引别名的问题就能比较优雅的解决。

旧索引称为A，新索引称为B，他们拥有共同的别名C，而业务层查询的索引名也是C。当新的全量索引B重建完成之后，只需要解除旧索引A与别名C关系，然后添加新索引B与别名C的关系，就能完成无缝切换，中间对用户是无感知的，如果B有问题，那么随时都可以重新解除B的关系并恢复A，这就完成了所谓的回滚操作，非常简单优雅。



### 优化

#### 禁用 wildcard 查询

wildcard查询：是使用通配符进行查询/正则表达式查询，其中“?”代表任意一个字符，“*”代表任意的一个或多个字符。

严重影响性能

#### force_merge 为什么能释放空间

elasticsearch是建立在Apache Lucene 基础上的实时分布式搜索引擎，Lucene为了提高搜索的实时性，采用不可再修改（immutable）方式将文档存储在一个个segment中。也就是说，一个segment在写入到存储系统之后，将不可以再修改。那么Lucene是如何从一个segment中删除一个被索引的文档呢？简单的讲，当用户发出命令删除一个被索引的文档#ABC时，该文档并不会被马上从相应的存储它的segment中删除掉，而是通过一个特殊的文件来标记该文档已被删除。当用户再次搜索到#ABC时，Elasticsearch在segment中仍能找到#ABC，但由于#ABC文档已经被标记为删除，所以Lucene会从发回给用户的搜索结果中剔除#ABC，所以给用户感觉的是#ABC已经被删除了。

我们已经知道在elasticsearch中每个shard每隔1秒都会refresh一次，每次refresh都会生成一个新的segment，按照这个速度过不了多久segment的数量就会爆炸，所以存在太多的segment是一个大问题，因为每一个segment都会占用文件句柄，内存资源，cpu资源，更加重要的是每一个搜索请求都必须访问每一个segment，这就意味着存在的segment越多，搜索请求就会变的更慢。

那么elaticsearch是如何解决这个问题呢？

根据ES的写入原理分析，默认每秒从memory buffer里面搬运数据到filesystem  cache，生产一个segments段，由后台程序定期分梯队进行合并，后台线程根据Lucene的合并规则定期进行segment merging合并操作，一般不需要用户担心或者采取任何行动。被删除的文档在segment合并时，才会被真正删除掉。在此之前，它仍然会占用着JVM heap和操作系统的文件cache等资源。在某些情况下，我们需要强制Elasticsearch进行segment merging，已释放其占用的大量系统资源。如果不加控制，合并一个大的segment会消耗比较多的io和cpu资源，同时也会搜索性能造成影响，所以默认情况下es已经对合并线程做了资源限额以便于它不会搜索性能造成太大影响。

- 限制如下：（不限制可以设置为 none）

  ```http
  PUT /_cluster/settings
  {
     "persistent" : {
         "indices.store.throttle.max_bytes_per_sec" : "100mb"
     }
  }
  ```

结合具体的业务，我们每次全量同步就会产生大量的segments，并标识为deleted，所以磁盘占用越来越大。因为ES还有定期合并功能，所以过一段时间还会再减少下来。

- 查看索引segments状态

  ```http
  GET _cat/segments/[index]?v
  ```

- forcemerge

  ```http
  POST /live_v4/_forcemerge?max_num_segments=1&only_expunge_deletes=true
  ```

  | 参数名称             | 说明                                                         |
  | -------------------- | ------------------------------------------------------------ |
  | max_num_segments     | 设置需要合并的段数。如果需要整个索引完全合并，则将该值设置为1。默认情况下会检查合并操作是否需要执行，如果需要才执行，否则就不执行。 |
  | only_expunge_deletes | 合并过程是否仅操作哪些包含了被删除文档的段，将这些段中未标识为删除的内容放到一个新创建的段中，然后将这些包含了被删除文档的段全部删除。<br/>注：这不会覆盖index.merge.policy.expunge_deletes_allowed阈值 |
  | flush                | 是否应在强制合并后执行刷新，默认为true。                     |

  _forcemerge 命令可强制进行segment合并，将要合并的segment读取出来，再写入到新的segment，然后删除所有标记为删除的文档。Segment merging要消耗CPU，以及大量的I/O资源，所以一定要在你的ElasticSearch集群处于维护窗口期间，并且有足够的I/O空间的（如：SSD）的条件下进行；否则很可能造成集群崩溃和数据丢失。

  为了保证合并顺利进行，在此期间暂停了所有对其进行的写操作，仅有少量的读操作。加大磁盘，或者限制索引合并的线程数量，减小每次合并的segment数量。

  这里需要注意: expunge操作是一种不得已而为之的操作，即在Elasticsearch不能有效自动清除删除文件的情况下才执行该操作。同时建议在此操作期间，最好停止对集群的所有读/写操作，并暂停止shard的自动分配 (cluster.routing.allocation.enable= none)，以防有节点被踢出后shard自动分配造成的数据丢失。



#### Shrink 减少主分片数

概念参考：[一般是结合rollover一起使用的，一开始没有看懂官方shrink文档，当看了这个之后就明白了](https://www.cnblogs.com/bonelee/p/8136708.html)

1. 使用场景

   - ES 5.x 后推出的一个新功能

   - 索引保存的数据量比较小， 需要重新设定主分片数

   - 索引从 Hot 移动到 Warm 后， 需要降低主分片数

2. 降低主分片数

   - 会使用和源索引相同的配置创建一个新的索引
   - 仅仅降低主分片数
   - 源分片数必须是目标分片数的倍数。
   - 如果源分片数是素数， 目标分片数只能为 1
   - 如果文件系统支持硬链接， 会将 Segments 硬连接到目标索引， 所以性能好
   - 完成后， 可以删除源索引（新索引已经存在全部数据）

3. 使用条件

   - 分片必须只读
   - 所有的分片必须在同一个节点上（因为硬链接不能跨磁盘工作，即使不在也可以调整到同一节点）
   - 集群健康状态为 Green
   - 目标索引必须不存在
   - 源主分片必须超过目标主分片
   - 源分片数必须是目标分片数的倍数。
   - 文档总数不能超过2,147,483,519
   - 保证有足够的空间，容纳第二个副本

4. Shrink 测试

   1. 创建index

      ```http
      PUT test
      {
        "settings": {
          "number_of_replicas": 0,
          "number_of_shards": 4
        }
      }
      ```

   2. 将主分片放置统一节点，并设为只读

      ```http
      PUT /test/_settings
      {
        "settings": {
          #使用自己的节点名
          "index.routing.allocation.require._name":"shrink_node_name",
          "index.blocks.write": true
        }
      }
      ```

   3. 查看节点分布

      ```http
      GET _cat/shards/test
      
      #结果
      test 3 p STARTED 0 283b 192.168.X.X elk-node01
      test 1 p STARTED 0 283b 192.168.X.X elk-node01
      test 2 p STARTED 0 283b 192.168.X.X elk-node01
      test 0 p STARTED 0 283b 192.168.X.X elk-node01
      ```

   4. 缩减分片

      ```http
      #缩减主分片
      POST test/_shrink/test1
      {
        "settings": {
          "index.number_of_replicas": 0,
          "index.number_of_shards": 2,
          "index.codec": "best_compression"
        },
        "aliases": {
          "test_indices": {}
        }
      }
       
      #分片均匀分布
      PUT /test1/_settings
      {
        "settings": {
          "index.routing.allocation.require._name":null,
          "index.blocks.write": null
        }
      }
       
      #添加副本
      PUT test1/_settings
      {
        "settings": {
          "number_of_replicas": 2
        }
      }
      ```

   5. 查看settings

      ```http
      GET test1/_settings
      ```

#### 索引生命周期管理

要素过多，包含了Rollover/Shrink等等。下面提供连接参考

1 - [一文详解elasticsearch的索引生命周期管理—rollover+curator—ilm](https://blog.csdn.net/microGP/article/details/114362960) 

2 - [Elasticsearch索引管理利器——Curator深入详解](https://blog.csdn.net/laoyang360/article/details/85882832) 









